---
title: "Critical Thinking Group 4 - HW5 - Wine"
author: "Sreejaya, Suman, Vuthy"
date: "November 15, 2016"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE, echo=FALSE)
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=80),tidy=TRUE)
options(scipen=999)
```


```{r, load libraries}
library(dplyr)
library(psych)
library(ggplot2)
library(gridExtra)
library(grid)
library(Amelia)
library(reshape2)
library(dummies)
library(car)
library(recommenderlab)
library(knitr)
library(faraway)
library(MASS)
```

# Overview
The objective of this assignment is to predict the number of cases of wine that will be sold based on the properties of the wine. A count regression model will be used to predict wine sales.

**Dataset**  
[Wine - Training data](https://raw.githubusercontent.com/Nguyver/DATA621-HW/master/HW5/wine-training-data.csv)  
[Wine - Evaluation Data](https://raw.githubusercontent.com/Nguyver/DATA621-HW/master/HW5/wine-evaluation-data.csv)  

## Data Exploration

```{r read data}
wine.trn  <- read.csv("https://raw.githubusercontent.com/Nguyver/DATA621-HW/master/HW5/wine-training-data.csv", header=TRUE, sep=",", stringsAsFactors = FALSE, na.strings=c("NA", ""))

wine.evl  <- read.csv("https://raw.githubusercontent.com/Nguyver/DATA621-HW/master/HW5/wine-evaluation-data.csv", header=TRUE, sep=",", stringsAsFactors = FALSE, na.strings=c("NA", ""))
```

```{r eval=FALSE}
summary(wine.trn)
glimpse(wine.trn)
```

Looks like the INDEX column name need to be corrected.
```{r}
colnames(wine.trn)[1] <- "INDEX"
```


### Missing Data

Eight of the variables have missing data.

```{r}
na_count <-sapply(wine.trn, function(y) sum(length(which(is.na(y)))))

na_countPrc <- round(sapply(wine.trn, function(y) sum(length(which(is.na(y))))/ length(y) *100), 2)

na.df <- filter(data.frame(ColName =colnames(wine.trn) , NA_Count=na_count, NA_Percent=na_countPrc), NA_Count > 0)

knitr::kable(filter(na.df, NA_Count > 0))

```

Lets explore more on the missing values here:

```{r}
#Though Amelia package is okay, the missmap visual is not easily interprettable, so, lets try with the below:

#http://www.njtierney.com/r/missing%20data/rbloggers/2015/12/01/ggplot-missing-data/
ggplot_missing <- function(x){
  
  x %>% 
    is.na %>%
    melt %>%
    ggplot(data = .,
           aes(x = Var2,
               y = Var1)) +
    geom_raster(aes(fill = value)) +
    scale_fill_grey(name = "",
                    labels = c("Present","Missing")) +
    theme_minimal() + 
    theme(axis.text.x  = element_text(angle=45, vjust=0.5)) + 
    labs(x = "Variables in Dataset",
         y = "Rows / observations")
}
```


```{r}
ggplot_missing(wine.trn)
```

Though there are lot of missing values, we could not see a definite pattern here, but we difinitely notice that there are highest number of missing values for *STARS* variable.


```{r}
ggplot(wine.trn, aes(x=factor(STARS), y=TARGET)) + geom_violin(aes(fill = factor(STARS))) + geom_boxplot(width=0.2)

ggplot(wine.trn, aes(x = TARGET, fill = factor(STARS))) + geom_density(alpha = 0.5)

```

From the above diagrams, we notice that the NAs for STARS showing us a different distribution. So, we have to take care of this in the data preparation.

### Data Distributions

Lets check the overall distribution of the TAGET variable ( which is a *count variable* indicating the number of sample cases):

```{r}
ggplot(wine.trn, aes(x=TARGET)) + geom_histogram(binwidth = 0.5)+ theme(axis.text=element_text(size=10), axis.title=element_text(size=10))
```

The above *TARGET* distribution has lot of *ZERO* values, which would indicate the *no sample cases purchased*, which could be due to NA values presence Or, some business reasons. But overall this appears close to *Poisson* distribution.


Lets check other variables distributions:

```{r}

#1. Remove INDEX variable
names(wine.trn)
wine.trn1 <- wine.trn[,-1]

#2.  Let us see WINE Data Histograms
#dev.off()
layout(matrix(1:15,3,5,byrow=TRUE))
#par(mfrow=c(3,5))
par(mar=c(2,1,2,1))
for (i in 1:ncol(wine.trn1))  hist(wine.trn1[,i],main = names(wine.trn1)[i])

#3.  now WINE Data Boxplot
layout(matrix(1:15,3,5,byrow=TRUE))
#par(mfrow=c(3,5))
par(mar=c(2,1,2,1))
for (i in 1:ncol(wine.trn1))  boxplot(wine.trn1[,i],main = names(wine.trn1)[i])
```

Majority of the variables appears to be numerical and normally distributed.Lets review the Ordinal variables here:

We have seen the *STARS* distribution previosly in *Missing Data* section, lets now review the *Acid Index*, and *LabelAppeal*, which can be treated as categorical similar to *STARS*: 

```{r}
#unique(wine.trn1$AcidIndex)
 
#check the distributions

#round(prop.table(table(wine.trn1$AcidIndex,wine.trn1$TARGET),1),2)
g1 <- ggplot(wine.trn, aes(x=factor(AcidIndex), y=TARGET)) + geom_violin(aes(fill = factor(AcidIndex))) 

#unique(wine.trn1$LabelAppeal)
#round(prop.table(table(wine.trn1$LabelAppeal,wine.trn1$TARGET),1),2)
g2 <- ggplot(wine.trn, aes(x=factor(LabelAppeal), y=TARGET)) + geom_violin(aes(fill = factor(LabelAppeal))) 

blank<-rectGrob(gp=gpar(col="white")) # make a white spacer grob
grid.arrange(g1, blank, g2, heights=c(0.7, 0.05, 0.25), nrow=3)

```


### Correlations

Lets visualize the correlation graph:

```{r}
#4.
library(PerformanceAnalytics)
cor.matrix <- cor(wine.trn1[,1:ncol(wine.trn1)], use= "complete.obs")
chart.Correlation(cor.matrix, histogram=TRUE, pch=25)
```

The above indicates the *STARS* and *LabelAppeal* are significant variables from correlation perspective. And *AcidIndex* and *VolatileAcidity* also got moderately correlated with the TARGET variable.


## Data Preparation

### Transform NAs

```{r}
wine.trn1$Alcohol[is.na(wine.trn1$Alcohol)] <- 0
wine.trn1$STARS[is.na(wine.trn1$STARS)] <- 0
```

### Factorize

```{r}
wine.trn1$STARS <- as.factor(wine.trn1$STARS)
wine.trn1$AcidIndex <- as.factor(wine.trn1$AcidIndex)
wine.trn1$LabelAppeal <- as.factor(wine.trn1$LabelAppeal)
```

lets take complete cases only, as we have got sufficient number of observations after we took care of the NAs for STARS and Alcohol variables.

```{r}
wine.trn.omit.na <- na.omit(wine.trn1)
glimpse(wine.trn.omit.na)
```

### Multicollinearity

Lets check for Multicollinearity in the predictors:

```{r}
full.pois <- glm(TARGET ~ ., data=wine.trn.omit.na, family=poisson())
#Lets check for Multi-Collinearity - lets find vif value and drop those that has 
vifFit1 <- faraway::vif(full.pois)
#sort by descending
vif.df <- as.data.frame(sort(vifFit1, decreasing = T))
names(vif.df) <- c('Multicolinearity score')
knitr::kable(vif.df)

#unique(wine.trn.omit.na$AcidIndex)

```

Multicollinearity noticed for AcidIndex dummy variables AcidIndex values 6, 7 , 8, 9, 10, 11, 12.

Lets try consolidating those rows and retry the vif again.

```{r}
wine.trn.omit.na$AcidIndex[wine.trn.omit.na$AcidIndex %in% c(6,7,8,9,10,11,12) ]<- 5
```

```{r}
full.pois <- glm(TARGET ~ ., data=wine.trn.omit.na, family=poisson())
#Lets check for Multi-Collinearity - lets find vif value and drop those that has 
vifFit1 <- faraway::vif(full.pois)
#sort by descending
vif.df <- as.data.frame(sort(vifFit1, decreasing = T))
names(vif.df) <- c('Multicolinearity score')
knitr::kable(vif.df)

#unique(wine.trn.omit.na$AcidIndex)
```

The above variables looks good enough to proceed with model building.

### Split the dataset into training and test:

We will randomly split our dataset into training (80%) and test (20%).

```{r echo=TRUE}
set.seed(3) 
s=sample(1:nrow(wine.trn.omit.na),0.80*nrow(wine.trn.omit.na)) 
wine.training=wine.trn.omit.na[s,] 
wine.test=wine.trn.omit.na[-s,]
```

Number of observations in *training* dataset is `r nrow(wine.training)` 

Number of observations in *test* dataset is `r nrow(wine.test)`

## Build  Models

### Poisson Model - Stepwise Backward

First, Include all variables and build the model. And then use the stepwise backward. 

```{r}
full.pois <- glm(TARGET ~ ., data=wine.training, family=poisson())
pois.backward.step = step(full.pois , trace = FALSE) 

summary(pois.backward.step) 
formula(pois.backward.step)
```

### Poisson Model - Stepwise Forward

```{r}
null.model.pois <- glm(TARGET ~ 1, data=wine.training, family=poisson())
pois.forward.step = step(null.model.pois ,
                         scope=list(lower=formula(null.model.pois),upper=formula(full.pois)),
                         direction = "forward",
                         trace = FALSE) 

summary(pois.forward.step) 
formula(pois.forward.step)
```

### Poisson Model - Manual

Lets include only significant predictors noticed from the data exploration section.

```{r}
full.pois.manual <- glm(TARGET ~ STARS +LabelAppeal +AcidIndex +VolatileAcidity, data=wine.training, family=poisson())
pois.manual = step(full.pois.manual , trace = FALSE) 

summary(pois.manual) 
formula(pois.manual)
```


### Negative Binomial Model - Stepwise Backward

Lets now try with Negative Binomial modeling, which fits greately for over-dispersed count outcome variables.

First, Include all variables and build the model. And then use the stepwise backward. 

```{r}
full.nbm <- glm.nb(TARGET ~ ., data=wine.training)
nbm.backward.step = step(full.nbm , trace = FALSE) 

summary(nbm.backward.step) 
formula(nbm.backward.step)
```

### Negative Binomial Model - Stepwise Forward

```{r}
null.model.nbm <- glm.nb(TARGET ~ 1, data=wine.training)
nbm.forward.step = step(null.model.nbm ,
                         scope=list(lower=formula(null.model.nbm),upper=formula(full.nbm)),
                         direction = "forward",
                         trace = FALSE) 

summary(nbm.forward.step) 
formula(nbm.forward.step)
```

### Negative Binomial Model - Manual

Lets include only significant predictors noticed from the data exploration section.

```{r}
full.nbm.manual <- glm.nb(TARGET ~ STARS +LabelAppeal +AcidIndex +VolatileAcidity, data=wine.training)
nbm.manual = step(full.nbm.manual , trace = FALSE) 

summary(nbm.manual) 
formula(nbm.manual)
```

### Linear Model - Stepwise Backward
```{r}
full.lm <- lm(TARGET ~ ., data=wine.training)
lm.backward.step = step(full.lm , trace = FALSE) 

summary(lm.backward.step) 
formula(lm.backward.step)
```


### Linear Model - Stepwise Forward
```{r}
nothing.mod.lnr <- lm(TARGET ~ 1, data=wine.training)
lm.forward.step <- step(nothing.mod.lnr, scope=list(lower=formula(nothing.mod.lnr),upper=formula(full.lm)), direction = 'forward', trace=FALSE)

summary(lm.forward.step)
formula(lm.forward.step)
```

### Linear Model - Manual
```{r}
full.lm.manual <- lm(TARGET ~ STARS +LabelAppeal +AcidIndex +VolatileAcidity, data=wine.training)
lm.manual = step(full.lm.manual , trace = FALSE) 

summary(lm.manual) 
formula(lm.manual)
```


## Model Selection

Lets prepare a validation results data frame by deriving the validation metrics like, RMSE, R^2 ( for linear model only) and AIC and number of coefficients etc., to help decide a better model out of the above 9 models.

```{r}
#RMSE - Root Mean Square Error ( / CrossValidation)
rmse <- function(testDataset, model) {
  return(round(sqrt(mean((predict(model,testDataset)-testDataset$TARGET)**2)),4))
}
```

```{r}
validationResults <- data.frame(ModelType=c("Poisson - Stepwise Backward",
                                            "Poisson - Stepwise Forward",
                                            "Poisson - Manual",
                                            "Negative Binomial - Backward",
                                            "Negative Binomial - Forward",
                                            "Negative Binomial - Manual",
                                            "Linear - Stepwise Backward",
                                            "Linear - Stepwise Forward",
                                            "Linear - Manual"
                                            ),
                                RMSE=c(rmse(wine.test, pois.backward.step),
                                       rmse(wine.test, pois.forward.step),
                                       rmse(wine.test, pois.manual),
                                       rmse(wine.test, nbm.backward.step),
                                       rmse(wine.test, nbm.forward.step),
                                       rmse(wine.test, nbm.manual),
                                       rmse(wine.test, lm.backward.step),
                                       rmse(wine.test, lm.forward.step),
                                       rmse(wine.test, lm.manual)),
                                Adj_R2=c(NA,NA,NA,NA,NA,NA,
                                     round(summary(lm.backward.step)$adj.r.squared,2),
                                     round(summary(lm.forward.step)$adj.r.squared,2),
                                     round(summary(lm.manual)$adj.r.squared,2)),
                                AIC=c(AIC(pois.backward.step),
                                      AIC(pois.forward.step),
                                      AIC(pois.manual),
                                      AIC(nbm.backward.step),
                                      AIC(nbm.forward.step),
                                      AIC(nbm.manual),
                                      AIC(lm.backward.step),
                                      AIC(lm.forward.step),
                                      AIC(lm.manual)),
                                Coefs=c(length(pois.backward.step$coefficients) - 1,
                                      length(pois.forward.step$coefficients) - 1,
                                      length(pois.manual$coefficients) - 1,
                                      length(nbm.backward.step$coefficients) - 1,
                                      length(nbm.forward.step$coefficients) - 1,
                                      length(nbm.manual$coefficients) - 1,
                                      length(lm.backward.step$coefficients) - 1,
                                      length(lm.forward.step$coefficients) - 1,
                                      length(lm.manual$coefficients) - 1)
)

kable(validationResults)
```

Since we are comparing different types of models, its tricky to select a common metric for these.

For our evaluation, lets consider the model that had least RMSE, AIC - which in our case is the linear model ( both barkward and forward resluted in the same metrics)

## Evaluation

Lets do the data transformation first for our eval data frame, and then predict.

```{r}
glimpse(wine.evl)
colnames(wine.evl)[1] <- "INDEX"
wine.evl$Alcohol[is.na(wine.evl$Alcohol)] <- 0
wine.evl$STARS[is.na(wine.evl$STARS)] <- 0

wine.evl$STARS <- as.factor(wine.evl$STARS)
wine.evl$AcidIndex <- as.factor(wine.evl$AcidIndex)
wine.evl$LabelAppeal <- as.factor(wine.evl$LabelAppeal)

wine.evl$LabelAppeal <- as.factor(wine.evl$LabelAppeal)

wine.evl$AcidIndex[wine.evl$AcidIndex %in% c(6,7,8,9,10,11,12) ]<- 5

wine.evl$TARGET <- round(predict(lm.backward.step, newdata=wine.evl, type="response"))


kable(wine.evl[,c("INDEX", "STARS", "LabelAppeal", "TARGET")])

```


## Appendix

```{r eval=FALSE, echo=TRUE, options(width = 80)}

```
