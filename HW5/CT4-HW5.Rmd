---
title: "Critical Thinking Group 4 - HW5 - Wine"
author: "Sreejaya, Suman, Vuthy"
date: "November 15, 2016"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE, echo=FALSE)
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=80),tidy=TRUE)
options(scipen=999)
```


```{r, load libraries}
library(dplyr)
library(psych)
library(ggplot2)
library(gridExtra)
library(grid)
library(Amelia)
library(reshape2)
library(dummies)
library(car)
library(recommenderlab)
library(knitr)
library(faraway)
library(MASS)
```

# Overview
The objective of this assignment is to predict the number of cases of wine that will be sold based on the properties of the wine. A count regression model will be used to predict wine sales.

**Dataset**  
[Wine - Training data](https://raw.githubusercontent.com/Nguyver/DATA621-HW/master/HW5/wine-training-data.csv)  
[Wine - Evaluation Data](https://raw.githubusercontent.com/Nguyver/DATA621-HW/master/HW5/wine-evaluation-data.csv)  

## Data Exploration

```{r read data}
wine.trn  <- read.csv("https://raw.githubusercontent.com/Nguyver/DATA621-HW/master/HW5/wine-training-data.csv", header=TRUE, sep=",", stringsAsFactors = FALSE, na.strings=c("NA", ""))

wine.evl  <- read.csv("https://raw.githubusercontent.com/Nguyver/DATA621-HW/master/HW5/wine-evaluation-data.csv", header=TRUE, sep=",", stringsAsFactors = FALSE, na.strings=c("NA", ""))
```

```{r eval=FALSE}
summary(wine.trn)
glimpse(wine.trn)
```

Looks like the INDEX column name need to be corrected.
```{r}
colnames(wine.trn)[1] <- "INDEX"
```


### Missing Data

Eight of the variables have missing data.

```{r}
na_count <-sapply(wine.trn, function(y) sum(length(which(is.na(y)))))

na_countPrc <- round(sapply(wine.trn, function(y) sum(length(which(is.na(y))))/ length(y) *100), 2)

na.df <- filter(data.frame(ColName =colnames(wine.trn) , NA_Count=na_count, NA_Percent=na_countPrc), NA_Count > 0)

knitr::kable(filter(na.df, NA_Count > 0))

```

Lets explore more on the missing values here:

```{r}
#Though Amelia package is okay, the missmap visual is not easily interprettable, so, lets try with the below:

#http://www.njtierney.com/r/missing%20data/rbloggers/2015/12/01/ggplot-missing-data/
ggplot_missing <- function(x){
  
  x %>% 
    is.na %>%
    melt %>%
    ggplot(data = .,
           aes(x = Var2,
               y = Var1)) +
    geom_raster(aes(fill = value)) +
    scale_fill_grey(name = "",
                    labels = c("Present","Missing")) +
    theme_minimal() + 
    theme(axis.text.x  = element_text(angle=45, vjust=0.5)) + 
    labs(x = "Variables in Dataset",
         y = "Rows / observations")
}
```


```{r}
ggplot_missing(wine.trn)
```

Though there are lot of missing values, we could not see a definite pattern here, but we difinitely notice that there are highest number of missing values for *STARS* variable.


```{r}
ggplot(wine.trn, aes(x=factor(STARS), y=TARGET)) + geom_violin(aes(fill = factor(STARS))) + geom_boxplot(width=0.2)

ggplot(wine.trn, aes(x = TARGET, fill = factor(STARS))) + geom_density(alpha = 0.5)

```

From the above diagrams, we notice that the NAs for STARS showing us a different distribution. So, we have to take care of this in the data preparation.

### Data Distributions

Lets check the overall distribution of the TAGET variable ( which is a *count variable* indicating the number of sample cases):

```{r}
ggplot(wine.trn, aes(x=TARGET)) + geom_histogram(binwidth = 0.5)+ theme(axis.text=element_text(size=10), axis.title=element_text(size=10))
```

The above *TARGET* distribution has lot of *ZERO* values, which would indicate the *no sample cases purchased*, which could be due to NA values presence Or, some business reasons. But overall this appears close to *Poisson* distribution.


Lets check other variables distributions:

```{r}

#1. Remove INDEX variable
names(wine.trn)
wine.trn1 <- wine.trn[,-1]

#2.  Let us see WINE Data Histograms
#dev.off()
layout(matrix(1:15,3,5,byrow=TRUE))
#par(mfrow=c(3,5))
par(mar=c(2,1,2,1))
for (i in 1:ncol(wine.trn1))  hist(wine.trn1[,i],main = names(wine.trn1)[i])

#3.  now WINE Data Boxplot
layout(matrix(1:15,3,5,byrow=TRUE))
#par(mfrow=c(3,5))
par(mar=c(2,1,2,1))
for (i in 1:ncol(wine.trn1))  boxplot(wine.trn1[,i],main = names(wine.trn1)[i])
```

Majority of the variables appears to be numerical and normally distributed.Lets review the Ordinal variables here:

We have seen the *STARS* distribution previosly in *Missing Data* section, lets now review the *Acid Index*, and *LabelAppeal*, which can be treated as categorical similar to *STARS*: 

```{r}
#unique(wine.trn1$AcidIndex)
 
#check the distributions

#round(prop.table(table(wine.trn1$AcidIndex,wine.trn1$TARGET),1),2)
g1 <- ggplot(wine.trn, aes(x=factor(AcidIndex), y=TARGET)) + geom_violin(aes(fill = factor(AcidIndex))) 

#unique(wine.trn1$LabelAppeal)
#round(prop.table(table(wine.trn1$LabelAppeal,wine.trn1$TARGET),1),2)
g2 <- ggplot(wine.trn, aes(x=factor(LabelAppeal), y=TARGET)) + geom_violin(aes(fill = factor(LabelAppeal))) 

blank<-rectGrob(gp=gpar(col="white")) # make a white spacer grob
grid.arrange(g1, blank, g2, heights=c(0.7, 0.05, 0.25), nrow=3)

```


### Correlations

Lets visualize the correlation graph:

```{r}
#4.
library(PerformanceAnalytics)
cor.matrix <- cor(wine.trn1[,1:ncol(wine.trn1)], use= "complete.obs")
chart.Correlation(cor.matrix, histogram=TRUE, pch=25)
```

The above indicates the *STARS* and *LabelAppeal* are significant variables from correlation perspective. And *AcidIndex* and *VolatileAcidity* also got moderately correlated with the TARGET variable.


## Data Preparation

### Transform NAs

```{r}
wine.trn1$Alcohol[is.na(wine.trn1$Alcohol)] <- 0
wine.trn1$STARS[is.na(wine.trn1$STARS)] <- 0
```

### Factorize

```{r}
wine.trn1$STARS <- as.factor(wine.trn1$STARS)
wine.trn1$AcidIndex <- as.factor(wine.trn1$AcidIndex)
wine.trn1$LabelAppeal <- as.factor(wine.trn1$LabelAppeal)
```

lets take complete cases only, as we have got sufficient number of observations after we took care of the NAs for STARS and Alcohol variables.

```{r}
wine.trn.omit.na <- na.omit(wine.trn1)
glimpse(wine.trn.omit.na)
```

### Multicollinearity

Lets check for Multicollinearity in the predictors:

```{r}
full.pois <- glm(TARGET ~ ., data=wine.trn.omit.na, family=poisson())
#Lets check for Multi-Collinearity - lets find vif value and drop those that has 
vifFit1 <- faraway::vif(full.pois)
#sort by descending
vif.df <- as.data.frame(sort(vifFit1, decreasing = T))
names(vif.df) <- c('Multicolinearity score')
knitr::kable(vif.df)

#unique(wine.trn.omit.na$AcidIndex)

```

Multicollinearity noticed for AcidIndex dummy variables AcidIndex values 6, 7 , 8, 9, 10, 11, 12.

Lets try consolidating those rows and retry the vif again.

```{r}
wine.trn.omit.na$AcidIndex[wine.trn.omit.na$AcidIndex %in% c(6,7,8,9,10,11,12) ]<- 5
```

```{r}
full.pois <- glm(TARGET ~ ., data=wine.trn.omit.na, family=poisson())
#Lets check for Multi-Collinearity - lets find vif value and drop those that has 
vifFit1 <- faraway::vif(full.pois)
#sort by descending
vif.df <- as.data.frame(sort(vifFit1, decreasing = T))
names(vif.df) <- c('Multicolinearity score')
knitr::kable(vif.df)

#unique(wine.trn.omit.na$AcidIndex)
```

The above variables looks good enough to proceed with model building.

### Split the dataset into training and test:

We will randomly split our dataset into training (80%) and test (20%).

```{r echo=TRUE}
set.seed(3) 
s=sample(1:nrow(wine.trn.omit.na),0.80*nrow(wine.trn.omit.na)) 
wine.training=wine.trn.omit.na[s,] 
wine.test=wine.trn.omit.na[-s,]
```

Number of observations in *training* dataset is `r nrow(wine.training)` 

Number of observations in *test* dataset is `r nrow(wine.test)`

## Build  Models

### Poisson Model - Stepwise Backward

First, Include all variables and build the model. And then use the stepwise backward. 

```{r}
#http://www.ats.ucla.edu/stat/r/dae/poissonreg.htm
#http://www.ats.ucla.edu/stat/r/dae/nbreg.htm

full.pois <- glm(TARGET ~ ., data=wine.training, family=poisson())
pois.backward.step = step(full.pois , trace = FALSE) 

round(summary(pois.backward.step)$coef,2)
formula(pois.backward.step)
```

We can notice that *STARS*, *LableAppeal*, *AcidIndex*, *VolatileAcidity* and  *TotalSulfurDioxide* are the significant variables.

For example, for each one-unit increase in VolatileAcidity, the expected log count of the number of sample units sold is decreases by 0.03.

The factor variable shown as STARS4 is the expected difference in log count between group 4 and the reference group zero (/NA).

Lets check if there is overdispersion (c-hat, to check if mean exceeding the variance) here, (Residual Deviance)/(Residual df).
(If c-hat is 1, then no overdispersion occur)

```{r}
#reference: http://theses.ulaval.ca/archimede/fichiers/21842/apa.html
```

c-hat for overdispersion check is `r deviance(pois.backward.step)/df.residual(pois.backward.step)`

### Poisson Model - Stepwise Forward

```{r}
null.model.pois <- glm(TARGET ~ 1, data=wine.training, family=poisson())
pois.forward.step = step(null.model.pois ,
                         scope=list(lower=formula(null.model.pois),upper=formula(full.pois)),
                         direction = "forward",
                         trace = FALSE) 

round(coef(summary(pois.forward.step)),2)
formula(pois.forward.step)
```

c-hat for overdispersion check is `r deviance(pois.forward.step)/df.residual(pois.forward.step)`

We notice the very similar results here. (Similar to Stepwise Backward), Hence the same interpretation applies here.

### Poisson Model - Manual

Lets include only significant predictors noticed from the data exploration section.

```{r}
full.pois.manual <- glm(TARGET ~ STARS +LabelAppeal +AcidIndex +VolatileAcidity, data=wine.training, family=poisson())
pois.manual = step(full.pois.manual , trace = FALSE) 

round(summary(pois.manual)$coef,2)
formula(pois.manual)
```

We only included the above significant variables we noticed from our correlation here, so this model has got 
few co-efficients compared with the above.

c-hat for overdispersion check is `r deviance(pois.manual)/df.residual(pois.manual)`

### Negative Binomial Model - Stepwise Backward

Lets now try with Negative Binomial modeling, which fits greately for over-dispersed count outcome variables.

First, Include all variables and build the model. And then use the stepwise backward. 

```{r}
full.nbm <- glm.nb(TARGET ~ ., data=wine.training)
nbm.backward.step = step(full.nbm , trace = FALSE) 

round(summary(nbm.backward.step)$coef,2)
formula(nbm.backward.step)
```

We noticed that our dataset do NOT has lot of overdispersion ( based on poission model above), so the negative binomial results are
very much close to the poission.

For example, for each one-unit increase in VolatileAcidity, the expected log count of the number of sample units sold is decreases by 0.031.

The factor variable shown as STARS1 is the expected difference [0.80] in log count between group 1 and the reference group zero (/NA).


### Negative Binomial Model - Stepwise Forward

```{r}
null.model.nbm <- glm.nb(TARGET ~ 1, data=wine.training)
nbm.forward.step = step(null.model.nbm ,
                         scope=list(lower=formula(null.model.nbm),upper=formula(full.nbm)),
                         direction = "forward",
                         trace = FALSE) 

round(summary(nbm.forward.step)$coef,2)
formula(nbm.forward.step)
```

This provides us with the similar results as Stepwise Backward.

### Negative Binomial Model - Manual

Lets include only significant predictors noticed from the data exploration section.

```{r}
full.nbm.manual <- glm.nb(TARGET ~ STARS +LabelAppeal +AcidIndex +VolatileAcidity, data=wine.training)
nbm.manual = step(full.nbm.manual , trace = FALSE) 

round(summary(nbm.manual)$coef,2)
formula(nbm.manual)
```

We only included the above significant variables we noticed from our correlation here, so this model has got 
few co-efficients compared with the above.


### Linear Model - Stepwise Backward

 Lets now just try with multiple linear regression model, and see the outcome.

```{r}
full.lm <- lm(TARGET ~ ., data=wine.training)
lm.backward.step = step(full.lm , trace = FALSE) 

round(summary(lm.backward.step)$coef,2)
formula(lm.backward.step)
```



### Linear Model - Stepwise Forward
```{r}
nothing.mod.lnr <- lm(TARGET ~ 1, data=wine.training)
lm.forward.step <- step(nothing.mod.lnr, scope=list(lower=formula(nothing.mod.lnr),upper=formula(full.lm)), direction = 'forward', trace=FALSE)

round(summary(lm.forward.step)$coef,2)
formula(lm.forward.step)
```

### Linear Model - Manual
```{r}
full.lm.manual <- lm(TARGET ~ STARS +LabelAppeal +AcidIndex +VolatileAcidity, data=wine.training)
lm.manual = step(full.lm.manual , trace = FALSE) 

round(summary(lm.manual)$coef,2)
formula(lm.manual)
```


## Model Selection

Lets prepare a validation results data frame by deriving the validation metrics like, RMSE, R^2 ( for linear model only) and AIC and number of coefficients etc., to help decide a better model out of the above 9 models.

```{r}
#RMSE - Root Mean Square Error ( / CrossValidation)
rmse <- function(testDataset, model) {
  return(round(sqrt(mean((predict(model,testDataset)-testDataset$TARGET)**2)),4))
}
```

```{r}
validationResults <- data.frame(ModelType=c("Poisson - Stepwise Backward",
                                            "Poisson - Stepwise Forward",
                                            "Poisson - Manual",
                                            "Negative Binomial - Backward",
                                            "Negative Binomial - Forward",
                                            "Negative Binomial - Manual",
                                            "Linear - Stepwise Backward",
                                            "Linear - Stepwise Forward",
                                            "Linear - Manual"
                                            ),
                                RMSE=c(rmse(wine.test, pois.backward.step),
                                       rmse(wine.test, pois.forward.step),
                                       rmse(wine.test, pois.manual),
                                       rmse(wine.test, nbm.backward.step),
                                       rmse(wine.test, nbm.forward.step),
                                       rmse(wine.test, nbm.manual),
                                       rmse(wine.test, lm.backward.step),
                                       rmse(wine.test, lm.forward.step),
                                       rmse(wine.test, lm.manual)),
                                Adj_R2=c(NA,NA,NA,NA,NA,NA,
                                     round(summary(lm.backward.step)$adj.r.squared,2),
                                     round(summary(lm.forward.step)$adj.r.squared,2),
                                     round(summary(lm.manual)$adj.r.squared,2)),
                                AIC=c(AIC(pois.backward.step),
                                      AIC(pois.forward.step),
                                      AIC(pois.manual),
                                      AIC(nbm.backward.step),
                                      AIC(nbm.forward.step),
                                      AIC(nbm.manual),
                                      AIC(lm.backward.step),
                                      AIC(lm.forward.step),
                                      AIC(lm.manual)),
                                Coefs=c(length(pois.backward.step$coefficients) - 1,
                                      length(pois.forward.step$coefficients) - 1,
                                      length(pois.manual$coefficients) - 1,
                                      length(nbm.backward.step$coefficients) - 1,
                                      length(nbm.forward.step$coefficients) - 1,
                                      length(nbm.manual$coefficients) - 1,
                                      length(lm.backward.step$coefficients) - 1,
                                      length(lm.forward.step$coefficients) - 1,
                                      length(lm.manual$coefficients) - 1)
)

kable(validationResults)
```

Since we are comparing different types of models, its tricky to select a common metric for these.

For our evaluation, lets consider the model that had least RMSE, AIC - which in our case is the linear model ( both barkward and forward resluted in the same metrics)

## Evaluation

Lets do the data transformation first for our eval data frame, and then predict.

```{r}
glimpse(wine.evl)
colnames(wine.evl)[1] <- "INDEX"
wine.evl$Alcohol[is.na(wine.evl$Alcohol)] <- 0
wine.evl$STARS[is.na(wine.evl$STARS)] <- 0

wine.evl$STARS <- as.factor(wine.evl$STARS)
wine.evl$AcidIndex <- as.factor(wine.evl$AcidIndex)
wine.evl$LabelAppeal <- as.factor(wine.evl$LabelAppeal)

wine.evl$LabelAppeal <- as.factor(wine.evl$LabelAppeal)

wine.evl$AcidIndex[wine.evl$AcidIndex %in% c(6,7,8,9,10,11,12) ]<- 5

wine.evl$TARGET <- round(predict(lm.backward.step, newdata=wine.evl, type="response"))


kable(wine.evl[,c("INDEX", "STARS", "LabelAppeal", "TARGET")])

```


## Appendix

```{r eval=FALSE, echo=TRUE, options(width = 80)}

```
