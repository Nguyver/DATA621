---
title: "Critical Thinking Group 4 - HW1"
author: "Sreejaya, Suman, Vuthy"
date: "September 12, 2016"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)
```

```{r, warning=FALSE, message=FALSE}
library(RCurl)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(psych)
library(reshape)
library(MASS)
library(car)
library(recommenderlab)
library(knitr)
```

#Purpose  

The purpose of this experiment is to try to predict the amount of wins for a baseball team using the (modified) moneyball dataset. This dataset contains approximately 2200 observations with 17 variables. Each observation represents the performance of a professional baseball team from 1871 to 2006. The statistics have been adjusted to match the performance of a 162 game season.  

Dataset:  
[Moneyball Training Data](https://github.com/Nguyver/DATA621-HW/blob/master/HW1/moneyball-training-data.csv)  
[Moneyball Evaluation Data](https://github.com/Nguyver/DATA621-HW/blob/master/HW1/moneyball-evaluation-data.csv)

#1. Data Exploration

```{r}
#read directly from the github
moneyballTraining <- read.csv("https://raw.githubusercontent.com/Nguyver/DATA621-HW/master/HW1/moneyball-training-data.csv", header=TRUE, sep=",", stringsAsFactors = FALSE)
```

The dependent (response) variable is *TARGET_WINS*. Excluding INDEX, the rest of the variables are the independent variables (predictors). Lets review how each of these independent variables are distributed & how each of these indepdent variable relates to the response variable 'TARGET_WINS'.


##1.1 Missing Values
Review the *measure of the center* for the given variables. A quick look at the summary statistics indicate that there are missing values for some of the predictors.

```{r, warning=FALSE}
summary(moneyballTraining[3:17])
```

The list of predictor variables with missing data and their counts:

```{r, warning=FALSE, message=FALSE}
moneyball.NA <- apply(moneyballTraining[3:17], 2, function(x) sum(is.na(x)))
moneyball.missing <- cbind(moneyball.NA, moneyball.NA/nrow(moneyballTraining))
colnames(moneyball.missing) <- c('Missing', 'Percentage')
kable(moneyball.missing)
```

##1.2 Distribution of predictors
Review the distributions of the predictors. Here are few histograms of the predictors.

```{r, warning=FALSE, message=FALSE}
# Explore independent variable TEAM_BATTING_H
g_tbh <- ggplot(data = moneyballTraining) + geom_histogram(aes(x=TEAM_BATTING_H), binwidth = 0.5) + theme(axis.text=element_text(size=8), axis.title=element_text(size=8))

g_b2b <- ggplot(data = moneyballTraining) + geom_histogram(aes(x=TEAM_BATTING_2B), binwidth = 0.5) +  theme(axis.text=element_text(size=8), axis.title=element_text(size=8))

g_brsb <- ggplot(data = moneyballTraining) + geom_histogram(aes(x=TEAM_BASERUN_SB), binwidth = 0.5) +  theme(axis.text=element_text(size=8), axis.title=element_text(size=8))

g_tph <- ggplot(data = moneyballTraining) + geom_histogram(aes(x=TEAM_PITCHING_H), binwidth = 0.5) +  theme(axis.text=element_text(size=8), axis.title=element_text(size=8))

g_tps <- ggplot(data = moneyballTraining) + geom_histogram(aes(x=TEAM_PITCHING_SO), binwidth = 0.5) + theme(axis.text=element_text(size=8), axis.title=element_text(size=8))

g_tfe <- ggplot(data = moneyballTraining) + geom_histogram(aes(x=TEAM_FIELDING_E), binwidth = 0.5) + theme(axis.text=element_text(size=8),axis.title=element_text(size=8))

g_tfd <- ggplot(data = moneyballTraining) + geom_histogram(aes(x=TEAM_FIELDING_DP), binwidth = 0.5) + theme(axis.text=element_text(size=8),axis.title=element_text(size=8))

g_tbhr <- ggplot(data = moneyballTraining) + geom_histogram(aes(x=TEAM_BATTING_HR), binwidth = 0.5) + theme(axis.text=element_text(size=8),axis.title=element_text(size=8))

g_tphLg <- ggplot(data = moneyballTraining) + geom_histogram(aes(x=log(TEAM_PITCHING_H)), binwidth = 0.5) +  theme(axis.text=element_text(size=8), axis.title=element_text(size=8))

g_tpsLg <- ggplot(data = moneyballTraining) + geom_histogram(aes(x=log(TEAM_PITCHING_SO)), binwidth = 0.5) + theme(axis.text=element_text(size=8), axis.title=element_text(size=8))

grid.arrange(g_tbh, g_b2b,g_brsb, g_tph, g_tps, g_tfe,g_tfd,g_tbhr,g_tphLg,g_tpsLg, ncol=2)
```

Based on the summary of the data, and the histograms, there are outliers and the distributions of the few of the predictors are skewed. Notice that *TEAM_PITCHING_H* and *TEAM_PICTCHING_SO* distributions are not visible at all in the above diagram, so the log transformation has been applied in the above.

Lets also review the box plot's of the predictors.

```{r, warning=FALSE, message=FALSE}
meltMoneyBallTraining <- melt(moneyballTraining[3:17])
ggplot(meltMoneyBallTraining, aes(factor(variable), value)) + geom_boxplot() + facet_wrap(~variable, scale="free")  + theme(axis.text=element_text(size=8), axis.title=element_text(size=8))
```

##1.3 Standard Deviation

```{r}
getStandardDev <- function(moneyballTraining)
{
  stdDevs <- SD(moneyballTraining[3:17])
  par(mai=c(3,1.2,1,1))

  # transformed the y, due to high variances.
  barplot(stdDevs[order(stdDevs, decreasing = T)], log = "y", las=2, main="Std Dev of Predictors", xlab="", ylab="Log(SD)", cex.axis = 0.8, cex.names=0.8) 
  
  return(stdDevs)
}

std <- getStandardDev(moneyballTraining)
kable(as.data.frame(std))
```

##1.4 Correlation
Find correlation of Response variable with predictor variables
```{r}

corData <-  round(cor(moneyballTraining), 3)                    # rounding makes it easier to look at
t.corData <- t(corData[2,c(2:17)])   # we are only interested on correlation of Team win against all other predictors
moneyballTraining.cor <- melt(t.corData) # convert the wide format to long form for ease of read
moneyballTraining.cor <- moneyballTraining.cor[, 2:3]
colnames(moneyballTraining.cor) <- c('Variable', 'Correlation')

kable(moneyballTraining.cor)
## TEAM_BATTING_SO,TEAM_PITCHING_H,  TEAM_FIELDING_E  have negative correlation with total win. (which is expected)

#TEAM_PITCHING_SO,TEAM_FIELDING_DP (but this should be positive)

## TEAM_BASERUN_CS, TEAM_BATTING_HBP have very low correlation with Total win. So we dont have to consider these variables in the MODEL
```
  
From the above we can see that the *TEAM_BATTING_H* is high positively correlated, and *TEAM_FIELDING_E* has the  negative corelation with the *TARGET_WINS*. Lets just visualize these two:

```{r, warning=FALSE, message=FALSE}
g1 = ggplot(data = moneyballTraining) + geom_point(aes(x=TEAM_BATTING_H, y= TARGET_WINS), alpha = 0.2, color="blue") + ggtitle("TARGET WINS  Vs TEAM_BATTING_H") 

g2 = ggplot(data = moneyballTraining) + geom_point(aes(x=TEAM_FIELDING_E, y= TARGET_WINS), alpha = 0.2, color="red") + ggtitle("TARGET WINS  Vs TEAM_FIELDING_E") 
 
grid.arrange(g1, g2, nrow=2)
#similarly other specific independent variables Vs target wins correlation diagram
```

#2. Data Preparation

##2.1.Eliminate variables with most missing data

It is clear from the dataset 'moneyball.missing'  that 'TEAM BATTING HBP' has more than 90% missing items. 
So we are removing the variable from the dataset.

```{r}
moneyballTraining <- subset(moneyballTraining, select = -TEAM_BATTING_HBP )
```

##2.2 Imputation of missing data

We have noticed that there are missing values for predictors, lets impute of missing values with mean.

```{r}
#Replacing Missing Values In dataset with column mean
for(i in 1:ncol(moneyballTraining)){
  moneyballTraining[is.na(moneyballTraining[,i]), i] <- mean(moneyballTraining[,i], na.rm = TRUE)
}
```

After imputation, the missing values should not be there.

```{r}
mb.imp <- apply(moneyballTraining[3:16], 2, function(x) sum(is.na(x)))
#colnames(mb.imp) <- c('# Missing')
kable(as.data.frame(mb.imp))
```

Correlation of response variable to predictor variable after imputing data
```{r}
corData.imp <-  round(cor(moneyballTraining), 3)                    # rounding makes it easier to look at
t.corData.imp <- t(corData.imp[2,c(2:16)])   # we are only interested on correlation of Team win against all other predictors
moneyballTraining.cor.imp <- melt(t.corData.imp) # convert the wide format to long form for ease of read
moneyballTraining.cor.imp <- moneyballTraining.cor.imp[, 2:3]

colnames(moneyballTraining.cor.imp) <- c('Variable', 'Correlation')
kable(moneyballTraining.cor.imp)
```


#3. Build  Models


Lets try to build different models to predict the *TARTGET_WINS*. The first thing we would like to do is to split our given dataset into 'training' and 'test' datasets.

Lets take sample of 75% observations into *training* bucket, which we will use for the model building, and the remaining 25% into *test* bucket, which can be used to compare the model predictions with the actuals. 

```{r}
set.seed(11)
samples <- sample(1:nrow(moneyballTraining), 0.75*nrow(moneyballTraining))
moneyballTraining <- moneyballTraining[samples,]
moneyballTest <- moneyballTraining[-samples,]
```

Number of observations in *training* dataset is `r nrow(moneyballTraining)`
Number of observations in *test* dataset is `r nrow(moneyballTest)`


The below are the few different approaches we will try to build the models:

  1. Manual elimination
  2. Stepwise Regression
  3. Stepwise Backward
  4. Stepwise Forward
  5. High Variance Inflation Factor (VIF) , high p-value predictors elimination.


## 3.1 Manual elimination

Lets try to fit a multiple linear regression model with TARGET_WINS as the response variable all the other predictors as the explanatory variables except 'TEAM BASERUN CS','TEAM BATTING HBP','TEAM BATTING SO' as they have very low correlation with Wins:
(Note: Since we do not need INDEX field, We will be removing INDEX data element from the model building)

The coefficients are:

```{r, warning=FALSE, message=FALSE}
options(stringsAsFactors = FALSE)
results <- data.frame( character(),  numeric())

#Full Model
model.manualElimination <- lm(formula = TARGET_WINS ~ . -INDEX -TEAM_BASERUN_CS -TEAM_BATTING_SO,data =moneyballTraining)

summary(model.manualElimination)$coefficients[,4] 

ar1 <-  summary(model.manualElimination)$adj.r.squared

results <- rbind(results, c("Manual Elimination", round(ar1 * 100, 2)))
par(mfrow=c(2, 2))
graphics::plot(model.manualElimination, main="Manual elimination")
```

*The adjusted r-squared values is `r ar1`*

In the residuals Vs Fitted graph, the red line is about flat, which indicates the linearity in residuals is good. In the scale-location graph as well, the red line is about flat, which indicates that residual variance is constant [homo scadasticity assumption]. The Normal Q-Q graph indicates that the most of the residuals are on the straight line.However, the Residual Vs Leverage plot has the redline not alligned with gray dotted line, this indicates that the assumption of standardized residuals centered around zero is NOT true here.

##3.2 Stepwise Regression

Here, we will be selecting the predictors based on stepwise regression. 

The coefficients we obtained here are:

```{r, message=FALSE, warning=FALSE}
fit <- lm(formula = TARGET_WINS ~. -INDEX , data =moneyballTraining)

# Stepwise Regression
model.step <- stepAIC(fit, direction="both", trace=FALSE)
summary(model.step)$coefficients[,4] 

ar2 <-  summary(model.step)$adj.r.squared

results <- rbind(results, c("Stepwise Regression", round(ar2 * 100, 2)))

par(mfrow=c(2, 2))
graphics::plot(model.step, main="Stepwise Regression")
```

*And the adjusted r-squared value is `r ar2`*

In the residuals Vs Fitted graph, the red line is about flat, which indicates the linearity in residuals is good. In the scale-location graph as well, the red line is about flat, which indicates that residual variance is  constant [homo scadasticity assumption]. The Normal Q-Q graph indicates that the most of the residuals are on the straight line. However, the Residual Vs Leverage plot has the redline not alligned with gray dotted line, this indicates that the assumption of standardized residuals centered around zero is NOT true here.

##3.3 Stepwise Backward   

The coefficients we obtained here are:

```{r, message=FALSE, warning=FALSE}
model.step.backward <- step(fit, direction="backward",trace=FALSE)
summary(model.step.backward)$coefficients[,4] 

ar3 <-  summary(model.step.backward)$adj.r.squared

results <- rbind(results, c("Stepwise Backward", round(ar3 * 100, 2)))

par(mfrow=c(2, 2))
graphics::plot(model.step.backward, main="Backward elimination")
```

*The adjusted r-squared value in the stepwise backward model is `r ar3`*

In the residuals Vs Fitted graph, the red line is about flat, which indicates the linearity in residuals is good. In the scale-location graph as well, the red line is about flat, which indicates that residual variance is constant [homo scadasticity assumption]. The Normal Q-Q graph indicates that the most of the residuals are on the straight line. However, the Residual Vs Leverage plot has the redline not alligned with gray dotted line, this indicates that the assumption of standardized residuals centered around zero is NOT true here.

##3.4 Stepwise Forward

The coefficients we obtained here are:

```{r}
forward.null <-lm(TARGET_WINS~ 1,data=moneyballTraining)
forward.full <-lm(TARGET_WINS~. -INDEX,data=moneyballTraining)
model.step.forward<- step(forward.null, scope=list(lower=forward.null, upper=forward.full), direction="forward", trace=FALSE)

summary(model.step.forward)$coefficients[,4] 
ar4 <-  summary(model.step.forward)$adj.r.squared

results <- rbind(results, c("Stepwise Forward", round(ar4 * 100, 2)))

par(mfrow=c(2, 2))
graphics::plot(model.step.forward, main="Forward Elimination")
```

*The adjusted r-squared value in the stepwise Forward model is `r ar4`*

In the residuals Vs Fitted graph, the red line is about flat, which indicates the linearity in residuals is good. In the scale-location graph as well, the red line is about flat, which indicates that residual variance is constant [homo scadasticity assumption]. The Normal Q-Q graph indicates that the most of the residuals are on the straight line. And notice here in the Residuals Vs Leverage graph, the standardized residuals are some what centered around zero. ( the red line stays closer to the horizontal gray dashed line, this indicates that the assumption of standardized residuals centered around zero holds true)

##3.5 Remove VIF, and high p value predictors manually.

 In this model we would be removing the multi-collinear predictors - basically removing the excessive correlation among the explanatory variables. And then try removing the high p value predictors ( > 0.05)

 The below is the VIF values, lets get rid of those that has got VIF > 5.
 
```{r, warning=FALSE, message= FALSE}
#Let's consider ALL the variables ( except INDEX).
fit1 <- lm(TARGET_WINS ~ . -INDEX, data=moneyballTraining)

#Lets check for Multi-Collinearity - lets find vif value and drop those that has 
#got high vif (>5)
vifFit1 <- vif(fit1)

#sort by descending
vif.df <- as.data.frame(sort(vifFit1, decreasing = T))
names(vif.df) <- c('VIF')
kable(vif.df)
```

Lets remove *TEAM_BATTING_HR TEAM_PITCHING_HR  TEAM_BATTING_BB TEAM_PITCHING_BB* , these highly corelated, which results in multi-colineary among these variables, lets get rid of these from the model building. 

```{r, warning=FALSE, message=FALSE}
fit2 <- lm(TARGET_WINS ~ .-INDEX -TEAM_BATTING_HR -TEAM_PITCHING_HR -TEAM_BATTING_BB -TEAM_PITCHING_BB, data=moneyballTraining)
```

These predictors:  *TEAM_BATTING_3B, TEAM_BATTING_2B, TEAM_BATTING_SO, TEAM_BATTING_HBP, TEAM_PITCHING_H, TEAM_PITCHING_SO* has got high p value, so, lets try removing and re-build the model:

Here are the final co-efficients we got:
```{r, warning=FALSE, message=FALSE}
model.vif <- lm(TARGET_WINS ~ .-INDEX -TEAM_BATTING_HR -TEAM_PITCHING_HR -TEAM_BATTING_BB -TEAM_PITCHING_BB -TEAM_BATTING_3B -TEAM_BATTING_2B -TEAM_BATTING_SO  -TEAM_PITCHING_H -TEAM_PITCHING_SO, data=moneyballTraining)

ar5 <-  summary(model.vif)$adj.r.squared
summary(model.vif)$coefficients[,4] 

results <- rbind(results, c("VIF Elimination", round(ar5 * 100, 2)))

par(mfrow=c(2, 2))
graphics::plot(model.vif, main="VIF")
```

*The adjusted r-squared value we got from the above model is `r ar5`*

In the residuals Vs Fitted graph, the red line is about flat, which indicates the linearity in residuals is good. In the scale-location graph as well, the red line is about flat, which indicates that residual variance is constant [homo scadasticity assumption]. The Normal Q-Q graph indicates that the most of the residuals are on the straight line (so, errors are normally distributed). And notice here in the Residuals Vs Leverage graph, the standardized residuals are centered around zero. ( the red line stays closer to the horizontal gray dashed line, this indicates that the assumption of standardized residuals centered around zero is good)

# 4. Selection

Lets now check to see how each model performed, by looking at the adjusted r-sqaured, RMSE values.

##4.1. Adjusted R-Square

Here is the adjusted R-Sqaured values from different model above:

```{r}
colnames(results) <- c("Method", "Adj R Squared")
kable(results)
```

Based on our diagnostic observations ( assumption of linearity, normality in residuals) from the above models, combined with the above Adj R squared values, we shortlist these 2 model for further validation:

  1. Stepwise Forward
  2. High Variance Inflation Factor (VIF) , high p-value predictors elimination. 

##4.2. RMSE - Root Mean Sqared Error (verification with test data)

Lets take our shortlisted models, and apply it on our *test data set*, and compare it with the actuals.

```{r}
#Lets take our model, and apply it on the test dataset.
predicted.wins <- predict(model.step.forward, newdata = moneyballTest)

#Lets calculate the RMSE
residuals <- moneyballTest$TARGET_WINS - predicted.wins
rmse_forward <- sqrt(mean(residuals^2))

#lets put in ggplot
rmse.df <- data.frame(actual = moneyballTest$TARGET_WINS, predicted = predicted.wins)
ggplot(rmse.df, aes(x=actual, y = predicted)) + geom_point() + geom_smooth() + ggtitle("Forward Regr Model- Predicted Vs Actual")
```

*The RMSE in Stepwise Forward Model is `r rmse_forward`*

Lets validate the model where we removed the high VIF variables (multicollinearity) :

```{r}
#Lets take our model, and apply it on the test dataset.
predicted.wins2 <- predict(model.vif, newdata = moneyballTest)

#Lets calculate the RMSE
residuals2 <- moneyballTest$TARGET_WINS - predicted.wins2
rmse_vif <- sqrt(mean(residuals2^2))

#lets put in ggplot
rmse.df2 <- data.frame(actual = moneyballTest$TARGET_WINS, predicted = predicted.wins2)
ggplot(rmse.df2, aes(x=actual, y = predicted)) + geom_point() + geom_smooth() + ggtitle("VIF Remove model - Predicted Vs Actual")
```

*The RMSE in Stepwise Forward Model is `r rmse_vif`*

##4.3. Conclusion

*Both the models performed similar, however RMSE is slightly lower in the Stepwise Forward model, so we will consider that model as a best fit for our evaluation.*


# 5. Evaluation

We will load the evaluation dataset , and predict the *TARGET_WINS* by applying our final model.

The given evaluation dataset has 259 observations, and the below are the missing values:

```{r, warning=FALSE, message=FALSE}
moneyballEvaluation <- read.csv("https://raw.githubusercontent.com/Nguyver/DATA621-HW/master/HW1/moneyball-evaluation-data.csv", header=TRUE, sep=",", stringsAsFactors = FALSE)

#check how many na's for each column
apply(moneyballEvaluation, 2, function(x) sum(is.na(x)))
```

Lets replace the missing values with column mean & predict.

```{r, warning=FALSE, message=FALSE}
#Replacing Missing Values In dataset with column mean
for(i in 1:ncol(moneyballEvaluation)){
  moneyballEvaluation[is.na(moneyballEvaluation[,i]), i] <- mean(moneyballEvaluation[,i], na.rm = TRUE)
}

moneyballEvaluation$PredictedWins <- round(predict(model.step.forward, newdata = moneyballEvaluation))

#write.csv(file="moneyballEvaluation_Predictions.csv", moneyballEvaluation)
```

[Click here to view the Predictions for Evaluation File](https://github.com/Nguyver/DATA621-HW/blob/master/HW1/moneyballEvaluation_Predictions.csv)  




# A. Appendix

```{r eval=FALSE, echo=TRUE, options(width = 80)}

library(RCurl)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(gridExtra)
library(psych)
library(reshape)
library(MASS)
library(car)
library(recommenderlab)
library(knitr)
#opts_chunk$set(tidy.opts=list(width.cutoff=80),tidy=TRUE)

moneyballTraining <- read.csv("https://raw.githubusercontent.com/Nguyver/DATA621-HW/master/HW1/moneyball-training-data.csv", header=TRUE, sep=",", stringsAsFactors = FALSE)

summary(moneyballTraining[3:17])

moneyball.NA <- apply(moneyballTraining[3:17], 2, function(x) sum(is.na(x)))
moneyball.missing <- cbind(moneyball.NA, moneyball.NA/nrow(moneyballTraining))
colnames(moneyball.missing) <- c('Missing', 'Percentage')
kable(moneyball.missing)

# Explore independent variable TEAM_BATTING_H
g_tbh <- ggplot(data = moneyballTraining) + geom_histogram(aes(x=TEAM_BATTING_H), binwidth = 0.5) + theme(axis.text=element_text(size=8), axis.title=element_text(size=8))

g_b2b <- ggplot(data = moneyballTraining) + geom_histogram(aes(x=TEAM_BATTING_2B), binwidth = 0.5) +  theme(axis.text=element_text(size=8), axis.title=element_text(size=8))

g_brsb <- ggplot(data = moneyballTraining) + geom_histogram(aes(x=TEAM_BASERUN_SB), binwidth = 0.5) +  theme(axis.text=element_text(size=8), axis.title=element_text(size=8))

g_tph <- ggplot(data = moneyballTraining) + geom_histogram(aes(x=TEAM_PITCHING_H), binwidth = 0.5) +  theme(axis.text=element_text(size=8), axis.title=element_text(size=8))

g_tps <- ggplot(data = moneyballTraining) + geom_histogram(aes(x=TEAM_PITCHING_SO), binwidth = 0.5) + theme(axis.text=element_text(size=8), axis.title=element_text(size=8))

g_tfe <- ggplot(data = moneyballTraining) + geom_histogram(aes(x=TEAM_FIELDING_E), binwidth = 0.5) + theme(axis.text=element_text(size=8),axis.title=element_text(size=8))

g_tfd <- ggplot(data = moneyballTraining) + geom_histogram(aes(x=TEAM_FIELDING_DP), binwidth = 0.5) + theme(axis.text=element_text(size=8),axis.title=element_text(size=8))

g_tbhr <- ggplot(data = moneyballTraining) + geom_histogram(aes(x=TEAM_BATTING_HR), binwidth = 0.5) + theme(axis.text=element_text(size=8),axis.title=element_text(size=8))

g_tphLg <- ggplot(data = moneyballTraining) + geom_histogram(aes(x=log(TEAM_PITCHING_H)), binwidth = 0.5) +  theme(axis.text=element_text(size=8), axis.title=element_text(size=8))

g_tpsLg <- ggplot(data = moneyballTraining) + geom_histogram(aes(x=log(TEAM_PITCHING_SO)), binwidth = 0.5) + theme(axis.text=element_text(size=8), axis.title=element_text(size=8))

grid.arrange(g_tbh, g_b2b,g_brsb, g_tph, g_tps, g_tfe,g_tfd,g_tbhr,g_tphLg,g_tpsLg, ncol=2)

meltMoneyBallTraining <- melt(moneyballTraining[3:17])
ggplot(meltMoneyBallTraining, aes(factor(variable), value)) + geom_boxplot() + facet_wrap(~variable, scale="free")  + theme(axis.text=element_text(size=8), axis.title=element_text(size=8))

getStandardDev <- function(moneyballTraining)
{
  stdDevs <- SD(moneyballTraining[3:17])
  par(mai=c(3,1.2,1,1))
  
  # transformed the y, due to high variances.
  barplot(stdDevs[order(stdDevs, decreasing = T)], log = "y", las=2, main="Std Dev of Predictors", xlab="", ylab="Log(SD)", cex.axis = 0.8, cex.names=0.8) 
  
  return(stdDevs)
}

std <- getStandardDev(moneyballTraining)
kable(as.data.frame(std))

corData <-  round(cor(moneyballTraining), 3)                    # rounding makes it easier to look at
t.corData <- t(corData[2,c(2:17)])   # we are only interested on correlation of Team win against all other predictors
moneyballTraining.cor <- melt(t.corData) # convert the wide format to long form for ease of read
moneyballTraining.cor <- moneyballTraining.cor[, 2:3]
colnames(moneyballTraining.cor) <- c('Variable', 'Correlation')

kable(moneyballTraining.cor)

g1 = ggplot(data = moneyballTraining) + geom_point(aes(x=TEAM_BATTING_H, y= TARGET_WINS), alpha = 0.2, color="blue") + ggtitle("TARGET WINS  Vs TEAM_BATTING_H") 

g2 = ggplot(data = moneyballTraining) + geom_point(aes(x=TEAM_FIELDING_E, y= TARGET_WINS), alpha = 0.2, color="red") + ggtitle("TARGET WINS  Vs TEAM_FIELDING_E") 

grid.arrange(g1, g2, nrow=2)
#similarly other specific independent variables Vs target wins correlation diagram


moneyballTraining <- subset(moneyballTraining, select = -TEAM_BATTING_HBP )

#Replacing Missing Values In dataset with column mean
for(i in 1:ncol(moneyballTraining)){
  moneyballTraining[is.na(moneyballTraining[,i]), i] <- mean(moneyballTraining[,i], na.rm = TRUE)
}

mb.imp <- apply(moneyballTraining[3:17], 2, function(x) sum(is.na(x)))
#colnames(mb.imp) <- c('# Missing')
kable(as.data.frame(mb.imp))

corData.imp <-  round(cor(moneyballTraining), 3)                    # rounding makes it easier to look at
t.corData.imp <- t(corData.imp[2,c(2:17)])   # we are only interested on correlation of Team win against all other predictors
moneyballTraining.cor.imp <- melt(t.corData.imp) # convert the wide format to long form for ease of read
moneyballTraining.cor.imp <- moneyballTraining.cor.imp[, 2:3]

colnames(moneyballTraining.cor.imp) <- c('Variable', 'Correlation')
kable(moneyballTraining.cor.imp)

set.seed(11)
samples <- sample(1:nrow(moneyballTraining), 0.75*nrow(moneyballTraining))
moneyballTraining <- moneyballTraining[samples,]
moneyballTest <- moneyballTraining[-samples,]

options(stringsAsFactors = FALSE)
results <- data.frame( character(),  numeric())

#Full Model
model.manualElimination <- lm(formula = TARGET_WINS ~ . -INDEX -TEAM_BASERUN_CS -TEAM_BATTING_SO,data =moneyballTraining)

summary(model.manualElimination)$coefficients[,4] 

ar1 <-  summary(model.manualElimination)$adj.r.squared

results <- rbind(results, c("Manual Elimination", round(ar1 * 100, 2)))
par(mfrow=c(2, 2))
graphics::plot(model.manualElimination, main="Manual elimination")

fit <- lm(formula = TARGET_WINS ~. -INDEX , data =moneyballTraining)

# Stepwise Regression
model.step <- stepAIC(fit, direction="both", trace=FALSE)
summary(model.step)$coefficients[,4] 

ar2 <-  summary(model.step)$adj.r.squared

results <- rbind(results, c("Stepwise Regression", round(ar2 * 100, 2)))

par(mfrow=c(2, 2))
graphics::plot(model.step, main="Stepwise Regression")

model.step.backward <- step(fit, direction="backward",trace=FALSE)
summary(model.step.backward)$coefficients[,4] 

ar3 <-  summary(model.step.backward)$adj.r.squared

results <- rbind(results, c("Stepwise Backward", round(ar3 * 100, 2)))

par(mfrow=c(2, 2))
graphics::plot(model.step.backward, main="Backward elimination")

forward.null <-lm(TARGET_WINS~ 1,data=moneyballTraining)
forward.full <-lm(TARGET_WINS~. -INDEX,data=moneyballTraining)
model.step.forward<- step(forward.null, scope=list(lower=forward.null, upper=forward.full), direction="forward", trace=FALSE)

summary(model.step.forward)$coefficients[,4] 
ar4 <-  summary(model.step.forward)$adj.r.squared

results <- rbind(results, c("Stepwise Forward", round(ar4 * 100, 2)))

par(mfrow=c(2, 2))
graphics::plot(model.step.forward, main="Forward Elimination")

#Let's consider ALL the variables ( except INDEX).
fit1 <- lm(TARGET_WINS ~ . -INDEX, data=moneyballTraining)

#Lets check for Multi-Collinearity - lets find vif value and drop those that has 
#got high vif (>5)
vifFit1 <- vif(fit1)

#sort by descending
vif.df <- as.data.frame(sort(vifFit1, decreasing = T))
names(vif.df) <- c('VIF')
kable(vif.df)

fit2 <- lm(TARGET_WINS ~ .-INDEX -TEAM_BATTING_HR -TEAM_PITCHING_HR -TEAM_BATTING_BB -TEAM_PITCHING_BB, data=moneyballTraining)

model.vif <- lm(TARGET_WINS ~ .-INDEX -TEAM_BATTING_HR -TEAM_PITCHING_HR -TEAM_BATTING_BB -TEAM_PITCHING_BB -TEAM_BATTING_3B -TEAM_BATTING_2B -TEAM_BATTING_SO  -TEAM_PITCHING_H -TEAM_PITCHING_SO, data=moneyballTraining)

ar5 <-  summary(model.vif)$adj.r.squared
summary(model.vif)$coefficients[,4] 

results <- rbind(results, c("VIF Elimination", round(ar5 * 100, 2)))

par(mfrow=c(2, 2))
graphics::plot(model.vif, main="VIF")

colnames(results) <- c("Method", "Adj R Squared")
kable(results)

#Lets take our model, and apply it on the test dataset.
predicted.wins <- predict(model.step.forward, newdata = moneyballTest)

#Lets calculate the RMSE
residuals <- moneyballTest$TARGET_WINS - predicted.wins
rmse_forward <- sqrt(mean(residuals^2))

#lets put in ggplot
rmse.df <- data.frame(actual = moneyballTest$TARGET_WINS, predicted = predicted.wins)
ggplot(rmse.df, aes(x=actual, y = predicted)) + geom_point() + geom_smooth() + ggtitle("Forward Regr Model- Predicted Vs Actual")

#Lets take our model, and apply it on the test dataset.
predicted.wins2 <- predict(model.vif, newdata = moneyballTest)

#Lets calculate the RMSE
residuals2 <- moneyballTest$TARGET_WINS - predicted.wins2
rmse_vif <- sqrt(mean(residuals2^2))

#lets put in ggplot
rmse.df2 <- data.frame(actual = moneyballTest$TARGET_WINS, predicted = predicted.wins2)
ggplot(rmse.df2, aes(x=actual, y = predicted)) + geom_point() + geom_smooth() + ggtitle("VIF Remove model - Predicted Vs Actual")

moneyballEvaluation <- read.csv("https://raw.githubusercontent.com/Nguyver/DATA621-HW/master/HW1/moneyball-evaluation-data.csv", header=TRUE, sep=",", stringsAsFactors = FALSE)

#check how many na's for each column
apply(moneyballEvaluation, 2, function(x) sum(is.na(x)))

#Replacing Missing Values In dataset with column mean
for(i in 1:ncol(moneyballEvaluation)){
  moneyballEvaluation[is.na(moneyballEvaluation[,i]), i] <- mean(moneyballEvaluation[,i], na.rm = TRUE)
}

moneyballEvaluation$PredictedWins <- round(predict(model.step.forward, newdata = moneyballEvaluation))

#write.csv(file="moneyballEvaluation_Predictions.csv", moneyballEvaluation)

```

