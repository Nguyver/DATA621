---
title: "Critical Thinking Group 4 - HW4 - Auto Insurance"
author: "Sreejaya, Suman, Vuthy"
date: "November 7, 2016"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE, echo=FALSE)
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=80),tidy=TRUE)
options(scipen=999)
options(expressions = 500000)
```


```{r, load libraries}
 library(dplyr)
 library(ggplot2)
 library(gridExtra)
# library(e1071)
 library(car)
 library(recommenderlab)
 library(knitr)
# library(Amelia)
# library(PerformanceAnalytics)
# library(robustbase)
# library(BMA)
# library(caret)
# library(pROC)
```

## Overview
The purpose of this project is to predict the probability that a person will crash their car and the amount of money it will cost if the person does crash their car using multiple linear regression and binary logistic regression models.  

**Dataset**  
[Insurance - Training data](https://raw.githubusercontent.com/Nguyver/DATA621-HW/master/HW4/insurance_training_data.csv)  
[Insurance - Evaluation Data](https://raw.githubusercontent.com/Nguyver/DATA621-HW/master/HW4/insurance-evaluation-data.csv)  

Below is a short description of the variables in the dataset.  

```{r}
desc <- 'data_desc.csv'

data_desc <- read.csv(desc)
kable(data_desc[,1:2])
```

## Data Exploration

```{r read data}
insurance.trn  <- read.csv("https://raw.githubusercontent.com/Nguyver/DATA621-HW/master/HW4/insurance_training_data.csv", header=TRUE, sep=",", stringsAsFactors = FALSE)

insurance.evl  <- read.csv("https://raw.githubusercontent.com/Nguyver/DATA621-HW/master/HW4/insurance-evaluation-data.csv", header=TRUE, sep=",", stringsAsFactors = FALSE)
```
The dataset contains roughly 8000 observations and 26 variables. Each record has two response variables. 

- TARGET_FLAG
- TARGET_AMT 

Running the glimpse() function on the dataset reveals a few issues with the data.  

Some data points have to be cleaned up

- INCOME
- HOME_VAL
- MSTATUS
- SEX
- EDUCATION
- JOB
- BLUEBOOK
- CAR_TYPE
- OLDCLAIM

A few variables need to be converted to factors

- TARGET_FLAG
- PARENT1
- MSTATUS
- SEX
- EDUCATION
- JOB
- CAR_USE
- CAR_TYPE
- RED_CAR
- REVOKED
- URBANICITY

A few variables need to be converted to integers

- INCOME
- HOME_VAL
- BLUEBOOK
- OLDCLAIM

```{r eval=FALSE}
glimpse(insurance.trn)
```
As with the glimpse() function, the summary() function reveals a few variables need to be coerced as well as a few missing values (NA).  
```{r eval=FALSE}
summary(insurance.trn)
```

```{r eval=FALSE}
### Visually assessing missing values: 
The Amelia package has a plotting function missmap() that will plot the dataset and highlight missing values:

missmap(insurance.trn, main = "Missing values vs observed")
```
The following variables have missing values:  

| Variable Name | # NA |
|---------------|------|
| AGE           | 6    |
| CAR_AGE       | 510  |
| YOJ           | 454  |


## Data Preparation

### Remove unnecessory variables:
"INDEX" is nothing more than an arbitrary identifier that provides no predictive value. It will be removed from the data set.  
```{r echo=TRUE}
insurance.trn$INDEX <- NULL
```

### Clean up data
Dollar signs and commas need to be removed from **INCOME, HOME_VAL, BLUEBOOK, OLDCLAIM**

```{r}
cleanUpAmounts <- function(amount) {
  return(as.numeric(gsub("\\$*|,", "", amount)))
}
insurance.trn$INCOME <- sapply(insurance.trn$INCOME, cleanUpAmounts)
insurance.trn$HOME_VAL <- sapply(insurance.trn$HOME_VAL, cleanUpAmounts)
insurance.trn$BLUEBOOK <- sapply(insurance.trn$BLUEBOOK, cleanUpAmounts)
insurance.trn$OLDCLAIM <- sapply(insurance.trn$OLDCLAIM, cleanUpAmounts)
```
'z_' will be removed from **MSTATUS, SEX, EDUCATION, JOB, CAR_TYPE**

```{r echo=TRUE}
cleanUpPrefix <- function(stringVal) {
  return(gsub('z_', '', stringVal))
}

insurance.trn$MSTATUS <- sapply(insurance.trn$MSTATUS, cleanUpPrefix)
insurance.trn$SEX <- sapply(insurance.trn$SEX, cleanUpPrefix)
insurance.trn$EDUCATION <- sapply(insurance.trn$EDUCATION, cleanUpPrefix)
insurance.trn$JOB <- sapply(insurance.trn$JOB, cleanUpPrefix)
insurance.trn$CAR_TYPE <- sapply(insurance.trn$CAR_TYPE, cleanUpPrefix)

```

### Factorize Variables:

Convert the **TARGET_FLAG, PARENT1, SEX, MSTATUS, EDUCATION, JOB, CAR_USE, CAR_TYPE, RED_CAR, REVOKED, URBANICITY** variables into factors:

```{r echo=TRUE}
insurance.trn$TARGET_FLAG <- as.factor(insurance.trn$TARGET_FLAG)
insurance.trn$PARENT1 <- as.factor(insurance.trn$PARENT1)
insurance.trn$SEX <- as.factor(insurance.trn$SEX)
insurance.trn$MSTATUS <- as.factor(insurance.trn$MSTATUS)
insurance.trn$EDUCATION <- as.factor(insurance.trn$EDUCATION)
insurance.trn$JOB <- as.factor(insurance.trn$JOB)
insurance.trn$CAR_USE <- as.factor(insurance.trn$CAR_USE)
insurance.trn$CAR_TYPE <- as.factor(insurance.trn$CAR_TYPE)
insurance.trn$RED_CAR <- as.factor(insurance.trn$RED_CAR)
insurance.trn$REVOKED <- as.factor(insurance.trn$REVOKED)
insurance.trn$URBANICITY <- as.factor(insurance.trn$URBANICITY)
```

```{r}
#insurance.trn$OLDCLAIM_YRLY_AVG <- insurance.trn$OLDCLAIM / 5
```

### Handling missing data 

*1. CAR_AGE - There are 510 NA's in CAR_AGE, so it is not a good idea to throw these records away.* 

```{r}
ggplot(data = insurance.trn) + geom_histogram(aes(x=CAR_AGE), binwidth = 0.5) + theme(axis.text=element_text(size=8), axis.title=element_text(size=8))
```
From the histogram, we see that CAR_AGE between 5 and 15 are the most common, But there is one record with negative value, which should be replaced. 
so filling in NA's/negative value  with  median(8) or mean(8.33) would be entirely reasonable. Let's fill in the NA's/negative value with the median value of 8: 

```{r}
(meanVal <- mean(insurance.trn$CAR_AGE, na.rm=TRUE))
(medianVal <- median(insurance.trn$CAR_AGE, na.rm=TRUE))

insurance.trn$CAR_AGE<- ifelse( insurance.trn$CAR_AGE <=0 , medianVal, insurance.trn$CAR_AGE)
insurance.trn$CAR_AGE<- ifelse(is.na( insurance.trn$CAR_AGE )==TRUE, medianVal, insurance.trn$CAR_AGE)

summary(insurance.trn$CAR_AGE)
```
So, as shown above, after we imputing the CAR_AGE, the mean value is consistent/close to the original mean.

*2. YOJ - There are 454 NA's in YOJ, so it is not a good idea to throw these records away.*  

```{r}
ggplot(data = insurance.trn) + geom_histogram(aes(x=YOJ), binwidth = 0.5) + theme(axis.text=element_text(size=8), axis.title=element_text(size=10))
```
From the histogram, we see that YOJ between 8 and 12 are the most common, so filling in NA's  with  mean(10.5) or median(11) would be entirely reasonable.
Let's fill in the NA's with the median 11:
```{r}
(medianVal <- median(insurance.trn$YOJ, na.rm=TRUE))

insurance.trn$YOJ<- ifelse(is.na( insurance.trn$YOJ )==TRUE, medianVal, insurance.trn$YOJ)

summary(insurance.trn$YOJ)
```

*3. AGE - Let us consider outliars for AGE before removing NA's* 

```{r}
boxAge <- ggplot(data = insurance.trn) + geom_boxplot(aes(x=1, y=AGE)) + theme(axis.text=element_text(size=8), axis.title=element_text(size=10))
histAge <- ggplot(data = insurance.trn) + geom_histogram(aes(x=AGE), binwidth = 0.5) + theme(axis.text=element_text(size=8), axis.title=element_text(size=10))
grid.arrange(boxAge, histAge, ncol=2,  top = "AGE: Box Plot & Histogram")
```
Since the mean, and median are approximately equal to each other, data is approximately symmetrical and there are no outliars. Mean=44.79 and Median =45. So let's fill in the NA's with the median 45:
```{r}
(medianVal <- median(insurance.trn$AGE, na.rm=TRUE))

insurance.trn$AGE<- ifelse(is.na( insurance.trn$AGE )==TRUE, medianVal, insurance.trn$AGE)

summary(insurance.trn$AGE)

```

*4. INCOME - Transformation* 

```{r}
boxIncome <- ggplot(data = insurance.trn) + geom_boxplot(aes(x=1, y=INCOME)) + theme(axis.text=element_text(size=8), axis.title=element_text(size=10))
histIncome <- ggplot(data = insurance.trn) + geom_histogram(aes(x=INCOME)) + theme(axis.text=element_text(size=8), axis.title=element_text(size=10))
grid.arrange(boxIncome, histIncome, ncol=2,  top = "INCOME: Box Plot & Histogram")
```

From the above, its clear that the INCOME distribution is positively skewed, So, lets consider transforming it using log base 10.
```{r}
#reference: https://www.youtube.com/watch?v=_c3dVTRIK9c
Xfrmlog10 = function(x) {
   return (logb(x+1, 10))
}

#First lets put zeroes where its NA & then transform using signedlog10
insurance.trn$INCOME <- ifelse(is.na( insurance.trn$INCOME)==TRUE, 0, insurance.trn$INCOME)
insurance.trn$INCOME_LOG <- sapply(insurance.trn$INCOME, Xfrmlog10)

summary(insurance.trn$INCOME_LOG)

#Now impute the zeros with median
insurance.trn$INCOME_LOG<- ifelse(insurance.trn$INCOME_LOG ==0, median(insurance.trn$INCOME_LOG), insurance.trn$INCOME_LOG)

summary(insurance.trn$INCOME_LOG)

ggplot(data = insurance.trn) + geom_histogram(aes(x=INCOME_LOG), binwidth =0.1 ) + ggtitle("INCOME LOG base 10 - Hist")+ theme(axis.text=element_text(size=8), axis.title=element_text(size=10)) 
  
```

Though there is a slight negative skewness, overall this transformation looks better (nearly normal) than the original distribution.

*5. HOME_VAL - Transformation* 

```{r}
boxHomeVal <- ggplot(data = insurance.trn) + geom_boxplot(aes(x=1, y=HOME_VAL)) + theme(axis.text=element_text(size=8), axis.title=element_text(size=10))
histHomeVal <- ggplot(data = insurance.trn) + geom_histogram(aes(x=HOME_VAL)) + theme(axis.text=element_text(size=8), axis.title=element_text(size=10))
grid.arrange(boxHomeVal, histHomeVal, ncol=2,  top = "HOME_VAL: Box Plot & Histogram")
```

From the above, its clear that the HOME_VAL distribution is slightly positively skewed, So, lets consider transforming it using log base 10.
```{r}
#reference: https://www.youtube.com/watch?v=_c3dVTRIK9c

#First lets put zeroes where its NA & then transform using signedlog10
insurance.trn$HOME_VAL <- ifelse(is.na( insurance.trn$HOME_VAL)==TRUE, 0, insurance.trn$INCOME)
insurance.trn$HOME_VAL_LOG <- sapply(insurance.trn$HOME_VAL, Xfrmlog10)

summary(insurance.trn$HOME_VAL_LOG)

#Now impute the zeros with median
insurance.trn$HOME_VAL_LOG<- ifelse(insurance.trn$HOME_VAL_LOG ==0, median(insurance.trn$HOME_VAL_LOG), insurance.trn$HOME_VAL_LOG)

summary(insurance.trn$HOME_VAL_LOG)

ggplot(data = insurance.trn) + geom_histogram(aes(x=HOME_VAL_LOG), binwidth =0.1 ) + ggtitle("HOME_VAL_LOG - Hist")+ theme(axis.text=element_text(size=8), axis.title=element_text(size=10)) 
  
```

Though there is a slight negative skewness, overall this transformation looks better (nearly normal) than the original distribution.

### Dummy Variables

Look for dummy variables in the categorical variables:

We can chose to make n-1 dummy varaibles, Or, check if response behaviour is similar across frew of these categories and merge them.

*CAR USE - Commercial vehicles are driven more, so might increase probability of collision* 

```{r}
round(prop.table(table(insurance.trn$CAR_USE,insurance.trn$TARGET_FLAG),1),2)
```

```{r}
insurance.trn = insurance.trn %>% mutate(CARUSE_COMMERCIAL=as.numeric(CAR_USE=="Commercial"))  %>% select(-CAR_USE)
```

*EDUCATION - In theory more educated people tend to drive more safely* 

```{r}
table(insurance.trn$EDUCATION)
round(prop.table(table(insurance.trn$EDUCATION,insurance.trn$TARGET_FLAG),1),2)
```

Lets make a categorical variable  of HIGH EDUCATION Vs LOW EDUCATION LEVELS.
```{r}
insurance.trn = insurance.trn %>% mutate(EDU_BACH_MAST_PHD=as.numeric(EDUCATION %in% c("PhD", "Masters", "Bachelors")))  %>% select(-EDUCATION)
```

*JOB CATEGORY - In theory, white collar jobs tend to be safer* 

Lets check the *JOB* categorical variable:
```{r}
round(prop.table(table(insurance.trn$JOB,insurance.trn$TARGET_FLAG),1),2)
```

Lets make a categorical variable  of WHITE-COLLAR Vs Non-WHITE-COLLAR.
```{r}
insurance.trn = insurance.trn %>% mutate(JOB_WHITECOLLAR=as.numeric(JOB %in% c("Manager", "Lawyer", "Doctor", "Professional"))) %>% select(-JOB)
```

*KIDSDRIV - When teenagers drive your car, you are more likely to get into crashes*
```{r}
#KIDSDRIV is "number of driving children""
round(prop.table(table(insurance.trn$KIDSDRIV,insurance.trn$TARGET_FLAG),1),2)
```

So,lets split the one or 2 teenagers Vs 3 or 4 teenagers, that drive the car.
```{r}
insurance.trn = insurance.trn %>% mutate(KIDSDRIV_2=as.numeric(KIDSDRIV %in% c(1,2)),
                                         KIDSDRIV_4=as.numeric(KIDSDRIV %in% c(2,4))) %>% 
                                  select(-KIDSDRIV)
```

*MSTATUS - In theory, married people drive more safely*

```{r}
round(prop.table(table(insurance.trn$MSTATUS,insurance.trn$TARGET_FLAG),1),2)

insurance.trn = insurance.trn %>% mutate(MARRIED=as.numeric(MSTATUS  == "Yes")) %>% 
                                  select(-MSTATUS)
```

*RED_CAR - Urban legend says that red cars (especially red sports cars) are more risky. Is that true?*

```{r}
round(prop.table(table(insurance.trn$RED_CAR,insurance.trn$TARGET_FLAG),1),2)
round(prop.table(table(insurance.trn$CAR_TYPE,insurance.trn$TARGET_FLAG),1),2)
```

Lets have a category of red sports car to verify the above Urban legend statement.

```{r}
insurance.trn = insurance.trn %>% mutate(RED_SPORTS_CAR=as.numeric(RED_CAR  == "yes" & CAR_TYPE == 'Sports Car')) %>% 
                                  select(-RED_CAR)

round(prop.table(table(insurance.trn$RED_SPORTS_CAR,insurance.trn$TARGET_FLAG),1),2)
```


*REVOKED - If your license was revoked in the past 7 years, you probably are a more risky driver.*

```{r}
round(prop.table(table(insurance.trn$REVOKED,insurance.trn$TARGET_FLAG),1),2)

insurance.trn = insurance.trn %>% mutate(REVOKED=as.numeric(REVOKED  == "Yes" )) 

```

*SEX - Urban legend says that women have less crashes then men. Is that true?*

Lets just consider adding a dummy variable 'MALE' or not.
```{r}
round(prop.table(table(insurance.trn$SEX,insurance.trn$TARGET_FLAG),1),2)
insurance.trn = insurance.trn %>% mutate(MALE=as.numeric(SEX  == "M" ))  %>% select(-SEX)
```

*The other variables - BLUEBOOK,CAR_AGE,CAR_TYPE , has 'Unknown effect on probability of collision, but probably effect the payout if there is a crash', per data_desc*

We will leave the numeric variables BLUEBOOK, CAR_AGE 'as it is', and create the dummy variables for CAR_TYPE, so we would have the CAR_TYPE also numeric. 

```{r}
round(prop.table(table(insurance.trn$CAR_TYPE,insurance.trn$TARGET_FLAG),1),2)

insurance.trn = insurance.trn %>% mutate(CAR_TYPE_vAN=as.numeric(CAR_TYPE == "Van"),
                                         CAR_TYPE_SUV=as.numeric(CAR_TYPE == "SUV"),
                                         CAR_TYPE_SPORTS=as.numeric(CAR_TYPE == "Sports Car"),
                                         CAR_TYPE_PICKUP=as.numeric(CAR_TYPE == "Pickup"),
                                         CAR_TYPE_PANTRUCK=as.numeric(CAR_TYPE == "Panel Truck")) %>% 
                                  select(-CAR_TYPE)

```

*Single Parent - Unknown effect*

Lets make it numeric.

```{r}
round(prop.table(table(insurance.trn$PARENT1,insurance.trn$TARGET_FLAG),1),2)
insurance.trn = insurance.trn %>% mutate(PARENT1=as.numeric(PARENT1  == "Yes" ))
```

*URBANICITY - Home/Work Area*

Lets make it numeric.

```{r}
round(prop.table(table(insurance.trn$URBANICITY,insurance.trn$TARGET_FLAG),1),2)
insurance.trn = insurance.trn %>% mutate(URBAN=as.numeric(URBANICITY  == "Highly Urban/ Urban")) %>% 
                                  select(-URBANICITY)
```

After adding the dummy variables, here's a glimpse of our final dataset after dummy variables.

```{r}
glimpse(insurance.trn)
summary(insurance.trn)
```


Now , all of our data has got all numeric vas and ready for modelling process.

### Check for Multicolinearity in the predictors:

Check for Multicolinearity among the predictor variables and remove those with excessive correlation among the explanatory variables. 

```{r}

#alias(glm(TARGET_FLAG ~ .- TARGET_AMT, data=insurance.trn, family = "binomial"))
fit <- glm(TARGET_FLAG ~ .- TARGET_AMT, data=insurance.trn, family = "binomial")

#Lets check for Multi-Collinearity - lets find vif value and drop those that has 
vifFit1 <- vif(fit)

#sort by descending
vif.df <- as.data.frame(sort(vifFit1, decreasing = T))
names(vif.df) <- c('Multicolinearity score')
kable(vif.df)
```

From the above table, we do see multi-colinearity (with VIF > 10) among the predictors - INCOME and HOME_VAL_LOG, INCOME_LOG variables. 
Lets eliminate INCOME and see first:

```{r}
insurance.trn$INCOME <- NULL
fit <- glm(TARGET_FLAG ~ .- TARGET_AMT, data=insurance.trn, family = "binomial")

#Lets check for Multi-Collinearity - lets find vif value and drop those that has 
vifFit1 <- vif(fit)

#sort by descending
vif.df <- as.data.frame(sort(vifFit1, decreasing = T))
names(vif.df) <- c('Multicolinearity score')
kable(vif.df)
```

We still have got high VIF variables - HOME_VAL_LOG and INCOME_LOG. Lets try with HOME_VAL_LOG first.

```{r}
insurance.trn$HOME_VAL_LOG <- NULL
fit <- glm(TARGET_FLAG ~ .- TARGET_AMT, data=insurance.trn, family = "binomial")

#Lets check for Multi-Collinearity - lets find vif value and drop those that has 
vifFit1 <- vif(fit)

#sort by descending
vif.df <- as.data.frame(sort(vifFit1, decreasing = T))
names(vif.df) <- c('Multicolinearity score')
kable(vif.df)
```

Perfect, now all the VIF values are below 10, and we are good to proceed.

###Split the dataset into training and test:

We will randomly split our dataset into training (80%) and test (20%).

```{r echo=TRUE}
set.seed(999) 
s=sample(1:nrow(insurance.trn),0.80*nrow(insurance.trn)) 
insurance.training=insurance.trn[s,] 
insurance.test=insurance.trn[-s,]
```

Number of observations in *training* dataset is `r nrow(insurance.training)` 

Number of observations in *test* dataset is `r nrow(insurance.test)`


##3. Build  Models