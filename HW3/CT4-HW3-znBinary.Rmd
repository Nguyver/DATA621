---
title: "Critical Thinking Group 4 - HW3"
author: "Sreejaya, Suman, Vuthy"
date: "October 10, 2016"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE, echo=FALSE)
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=80),tidy=TRUE)
```

```{r, load libraries}
library(dplyr)
library(ggplot2)
library(car)
library(recommenderlab)
library(knitr)
library(PerformanceAnalytics)
library(Amelia)
library(robustbase)
library(BMA)
library(caret)
```

## Overview
The purpose of this project is to predict if a neighborhood will be at risk for high crime levels using binary logistic regression models. Below is a short description of the variables in the dataset.

- zn: proportion of residential land zoned for large lots (over 25000 square feet)
- indus: proportion of non-retail business acres per suburb
- chas: a dummy var. for whether the suburb borders the Charles River (1) or not (0)
- nox: nitrogen oxides concentration (parts per 10 million)
- rm: average number of rooms per dwelling
- age: proportion of owner-occupied units built prior to 1940
- dis: weighted mean of distances to five Boston employment centers
- rad: index of accessibility to radial highways
- tax: full-value property-tax rate per $10,000
- ptratio: pupil-teacher ratio by town
- black: 1000 $(B_k - 0.63)^2$ where Bk is the proportion of blacks by town
- lstat: lower status of the population (percent)
- medv: median value of owner-occupied homes in $1000s
- target: whether the crime rate is above the median crime rate (1) or not (0) (response variable)

Dataset  
[Crime - Training data](https://github.com/Nguyver/DATA621-HW/blob/master/HW3/crime-training-data.csv)  
[Crime - Evaluation Data](https://github.com/Nguyver/DATA621-HW/blob/master/HW3/crime-evaluation-data.csv)

## Data Exploration

- Move Histograms to data exploration (grid)
- do not remove variables based on correlation
- possibly remove "tables"

The dataset contains 466 observations and 14 variables. The response variable is the **target** variable. Below is a glimpse of the data.
```{r read data}
crime.trn  <- read.csv("https://raw.githubusercontent.com/Nguyver/DATA621-HW/master/HW3/crime-training-data.csv", header=TRUE, sep=",", stringsAsFactors = FALSE)

crime.evl  <- read.csv("https://raw.githubusercontent.com/Nguyver/DATA621-HW/master/HW3/crime-evaluation-data.csv", header=TRUE, sep=",", stringsAsFactors = FALSE)
```

```{r}
glimpse(crime.trn)
```

### A visual take on the missing values might be helpful: 
The Amelia package has a special plotting function missmap() that will plot your dataset and highlight missing values:
```{r}
missmap(crime.trn, main = "Missing values vs observed")
```
There are no missing values in the dataset.  

There appears to be no missing values. Lets plot the correlation between the variables.

```{r, warning=FALSE, message=FALSE}
cor.matrix <- cor(crime.trn[,1:ncol(crime.trn)])
chart.Correlation(cor.matrix, histogram=TRUE, pch=19)
```

From the above correlation matrix , the **target** variable seems to have correlation with 

  * zn    - proportion of residential land zoned for large lots 
  * indus - proportion of non-retail business acres per suburb 
  * nox   - nitrogen oxides concentration
  * age   - proportion of owner-occupied units built prior to 1940
  * dis   - weighted mean of distances to five Boston employment centers
  * rad   - index of accessibility to radial highways 
  * tax   - full-value property-tax rate per $10,000 
  * lstat - lower status of the population 


FIND A PLACE TO PUT THIS  
Two variables should be converted to factors.  

Lets look at each of the predictor variable's data:


```{r}
#proportion of residential land zoned for large lots

hist(crime.trn$zn, main="Histogram of zn", xlab="zn", border="blue", col="green", las=1)

#Lets look at the average response rate.
#gives %ges across rows , and rounded by 2 decimals.
```

From the above, it appears like majority of the neighborhoods have no residential land zoned for large lots. 

Similarly, let's proceed with others

```{r}
hist(crime.trn$indus, main="Histogram of Indus", xlab="indus", border="blue", col="green", las=1)
#round(prop.table(table(crime.trn.new$indus, crime.trn.new$target), 1),2)
```


```{r}
hist(crime.trn$nox, main="Histogram of nox", xlab="nox", border="blue", col="green", las=1)
#kable(round(prop.table(table(crime.trn.new$nox, crime.trn.new$target), 1),2))
```


```{r}
hist(crime.trn$age, main="Histogram of age", xlab="age", border="blue", col="green", las=1)
#hist(crime.trn.new$age, main="Histogram of age", xlab="age", border="blue", col="green", las=1)
#kable(round(prop.table(table(crime.trn.new$age, crime.trn.new$target), 1),2))
```

Looks like the buildings with age > 100 are mentioned as 100 in the above. We could not derive a specific categorization here, so, we leave the variable as is.


```{r}
hist(crime.trn$dis, main="Histogram of dis", xlab="dis", border="blue", col="green", las=1)
#hist(crime.trn.new$dis, main="Histogram of dis", xlab="dis", border="blue", col="green", las=1)
#kable(round(prop.table(table(crime.trn.new$dis, crime.trn.new$target), 1),2))
```

```{r}
hist(crime.trn$rad, main="Histogram of rad", xlab="rad", border="blue", col="green", las=1)
#hist(crime.trn.new$rad, main="Histogram of rad", xlab="rad", border="blue", col="green", las=1)
#kable(round(prop.table(table(crime.trn.new$rad, crime.trn.new$target), 1),2))
```

```{r}
hist(crime.trn$tax, main="Histogram of tax", xlab="tax", border="blue", col="green", las=1)
#hist(crime.trn.new$tax, main="Histogram of tax", xlab="tax", border="blue", col="green", las=1)
#kable(round(prop.table(table(crime.trn.new$tax, crime.trn.new$target), 1),2))
```

```{r}
hist(crime.trn$lstat, main="Histogram of lstat", xlab="lstat", border="blue", col="green", las=1)
#hist(crime.trn.new$lstat, main="Histogram of lstat", xlab="lstat", border="blue", col="green", las=1)
```  

## Data Preparation

- address multicolinearity
- change columns to factors
- zn variable
- train/test sets


```{r}
#length(crime.trn$zn)
#table(crime.trn$zn)
```
Out of 466 values 339 are zeros. So we would like to treat zn as binary, land size over 25,000 sq.ft as 1 and below 25,000 sq.ft as 0

```{r}
crime.trn$zn <- ifelse(crime.trn$zn>0, 1, 0)
table(crime.trn$zn)
```


Also, let's split our dataset into training (80%) and test (20%).

```{r}
set.seed(999) 
s=sample(1:nrow(crime.trn),0.80*nrow(crime.trn)) 
crime.train=crime.trn[s,] 
crime.test=crime.trn[-s,]
```

CONVERT INT to FACTORS
```{r}


```


## Build Models
- Clean up outputs
- explain coefficients
- AUC?

### 1. Backward elimination method 

family=binomial in the glm() function.
 1.  Let us start with all the parameters
```{r}
 fullmodel = glm(target ~.,family=binomial,data =crime.train)
 summary(fullmodel)
```

```{r}
backwards.model = step(fullmodel) # Backwards selection is the default
backwards.formula <- formula(backwards.model)
backwards.formula
summary(backwards.model)
```

### 2. Forward elimination method


2. without any parameter

```{r}
nothing <- glm(target ~ 1,family=binomial,data =crime.train)
summary(nothing)
```

```{r}
forwards.model = step(nothing,
scope=list(lower=formula(nothing),upper=formula(fullmodel)), direction="forward")
forwards.formula <- formula(forwards.model)
forwards.formula
summary(forwards.model)
```
From the above two models we can see that zn,& age are not statistically significant.
As for the statistically significant variables, rad & nox have  a strong positive association of crime rate while tax has a negative coefficient, suggests as all other variables being equal as tax increases crime rate decreases.


Both Forward and backward elimination models came up with the same model. We next remove variables of low significance.
We would drop out Zn and age from the above models.
```{r}
manual.model <- glm(target ~ nox + rad + tax + dis,family=binomial(link='logit'),data=crime.train)
summary(manual.model)
```

We would drop out distance from the above model since the p value is not significant. Now the new model:
```{r}
manual.model2 <- glm(target ~ nox + rad + tax ,family=binomial(link='logit'),data=crime.train)
summary(manual.model2)
```
A unit increase in index of accessibility to radial highways increses the log odds by 0.56. Also unit increase in nitrogen oxides concentration increases the logodds by 33.03, while increase in tax rate reduces the log odds by 0.008.

```{r}
par(mfrow=c(2, 2))
graphics::plot(manual.model2)
```
### 3.Bayesian Approach
```{r}
output <- bic.glm(target ~., data = crime.train, glm.family = "binomial")
summary(output)

# Posterior probability of each of 11  models (rest very small by
# comparison, so are omitted, change value of OR to see them)
 output$postprob
 output$label

# For each of 8 variables, probability they should be in the model
 output$names
 output$probne0
 
 imageplot.bma(output)
 output$postmean
 
```
From the above resuls it is clear nitrogen oxides concentration(nox), accessibility to radial highways(rad) and property-tax rate(tax) are the 3 variables -probability they should be in the model
The model is 
target ~ nox+rad+tax



## Select Models
### 1.  anova() function on the model to analyze the table of deviance
```{r}
 
anova(manual.model2, test="Chisq")
```
The difference between the null deviance and the residual deviance shows how our model is doing against the null model (a model with only the intercept). The wider this gap, the better.
Nitrogen oxides concentration is the least deviation, so this variable can be dropped from the model.

### 2. Specificity and Sensitivity

```{r}
fitted.results <- predict(manual.model2,newdata=subset(crime.test,select=c(4,8,9)),type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)
table(fitted.results)
table(crime.test$target)

crime.test$predicted <- fitted.results
crime.test$predicted <- factor(crime.test$predicted)
crime.test$target <- factor(crime.test$target)

#length(fitted.results)

#summary(crime.test)
#nrow(crime.test)
```

```{r}
round(sensitivity(crime.test$predicted, 
            crime.test$target, 
            positive="1"), 4)

round(specificity(crime.test$predicted, 
                   crime.test$target, 
                   negative="0"),4)

```



### 3. AUC 

```{r}

```


## Predictions


## Appendix